{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis and Exploration\n",
    "\n",
    "This notebook provides comprehensive analysis of the text classification datasets used in the preprocessing research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from src.data.loaders import DatasetLoader\n",
    "from src.utils.visualization import VisualizationUtils\n",
    "from src.utils.reproducibility import set_random_seeds\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "set_random_seeds(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration and Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset configuration\n",
    "with open('../../config/datasets.yaml', 'r') as f:\n",
    "    datasets_config = yaml.safe_load(f)\n",
    "\n",
    "# Initialize components\n",
    "loader = DatasetLoader(cache_dir='../../datasets/processed')\n",
    "visualizer = VisualizationUtils(output_dir='../../experiments/results/plots')\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Available dataset categories: {list(datasets_config['datasets'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset overview\n",
    "all_datasets = {}\n",
    "for category, datasets in datasets_config['datasets'].items():\n",
    "    for dataset_name, config in datasets.items():\n",
    "        all_datasets[dataset_name] = config\n",
    "        all_datasets[dataset_name]['category'] = category\n",
    "\n",
    "# Create overview DataFrame\n",
    "overview_data = []\n",
    "for name, config in all_datasets.items():\n",
    "    overview_data.append({\n",
    "        'Dataset': name,\n",
    "        'Category': config['category'],\n",
    "        'Source': config['source'],\n",
    "        'Task Type': config['task_type'],\n",
    "        'Max Samples': config['max_samples'],\n",
    "        'Target Column': config['target_column'],\n",
    "        'Text Columns': ', '.join(config['text_columns']),\n",
    "        'Quality Issues': ', '.join(config['quality_issues'])\n",
    "    })\n",
    "\n",
    "overview_df = pd.DataFrame(overview_data)\n",
    "print(\"Dataset Overview:\")\n",
    "display(overview_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Dataset Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Category distribution\n",
    "category_counts = overview_df['Category'].value_counts()\n",
    "axes[0, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Datasets by Quality Issue Category')\n",
    "\n",
    "# 2. Source distribution\n",
    "source_counts = overview_df['Source'].value_counts()\n",
    "axes[0, 1].bar(source_counts.index, source_counts.values, color='lightcoral', alpha=0.7)\n",
    "axes[0, 1].set_title('Datasets by Source')\n",
    "axes[0, 1].set_ylabel('Number of Datasets')\n",
    "\n",
    "# 3. Task type distribution\n",
    "task_counts = overview_df['Task Type'].value_counts()\n",
    "axes[1, 0].bar(task_counts.index, task_counts.values, color='lightblue', alpha=0.7)\n",
    "axes[1, 0].set_title('Datasets by Task Type')\n",
    "axes[1, 0].set_ylabel('Number of Datasets')\n",
    "\n",
    "# 4. Sample size distribution\n",
    "axes[1, 1].hist(overview_df['Max Samples'], bins=10, color='lightgreen', alpha=0.7)\n",
    "axes[1, 1].set_title('Distribution of Dataset Sizes')\n",
    "axes[1, 1].set_xlabel('Max Samples')\n",
    "axes[1, 1].set_ylabel('Number of Datasets')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Dataset Analysis\n",
    "\n",
    "Let's analyze each dataset category in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(dataset_name, config, category):\n",
    "    \"\"\"\n",
    "    Analyze a single dataset.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ANALYZING: {dataset_name.upper()} ({category})\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset\n",
    "        train_data, test_data = loader.load_dataset(dataset_name, config)\n",
    "        \n",
    "        print(f\"Dataset loaded successfully:\")\n",
    "        print(f\"  - Training samples: {len(train_data):,}\")\n",
    "        print(f\"  - Test samples: {len(test_data):,}\")\n",
    "        print(f\"  - Total samples: {len(train_data) + len(test_data):,}\")\n",
    "        \n",
    "        # Combine for analysis\n",
    "        full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "        \n",
    "        # Basic statistics\n",
    "        target_col = config['target_column']\n",
    "        text_cols = config['text_columns']\n",
    "        \n",
    "        print(f\"\\nTarget column: {target_col}\")\n",
    "        print(f\"Text columns: {text_cols}\")\n",
    "        \n",
    "        # Class distribution\n",
    "        if target_col in full_data.columns:\n",
    "            class_dist = full_data[target_col].value_counts().sort_index()\n",
    "            print(f\"\\nClass distribution:\")\n",
    "            for class_val, count in class_dist.items():\n",
    "                percentage = (count / len(full_data)) * 100\n",
    "                print(f\"  - Class {class_val}: {count:,} ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Check for imbalance\n",
    "            min_class_ratio = class_dist.min() / class_dist.max()\n",
    "            print(f\"\\nImbalance ratio (min/max): {min_class_ratio:.3f}\")\n",
    "            if min_class_ratio < 0.1:\n",
    "                print(\"  ‚ö†Ô∏è  Severe class imbalance detected\")\n",
    "            elif min_class_ratio < 0.3:\n",
    "                print(\"  ‚ö†Ô∏è  Moderate class imbalance detected\")\n",
    "            else:\n",
    "                print(\"  ‚úÖ Classes are relatively balanced\")\n",
    "        \n",
    "        # Text analysis\n",
    "        for text_col in text_cols:\n",
    "            if text_col in full_data.columns:\n",
    "                print(f\"\\nText analysis for '{text_col}':\")\n",
    "                \n",
    "                # Text length statistics\n",
    "                text_lengths = full_data[text_col].astype(str).str.len()\n",
    "                print(f\"  - Mean length: {text_lengths.mean():.1f} characters\")\n",
    "                print(f\"  - Median length: {text_lengths.median():.1f} characters\")\n",
    "                print(f\"  - Min length: {text_lengths.min()} characters\")\n",
    "                print(f\"  - Max length: {text_lengths.max()} characters\")\n",
    "                print(f\"  - Std deviation: {text_lengths.std():.1f} characters\")\n",
    "                \n",
    "                # Word count statistics\n",
    "                word_counts = full_data[text_col].astype(str).str.split().str.len()\n",
    "                print(f\"  - Mean word count: {word_counts.mean():.1f} words\")\n",
    "                print(f\"  - Median word count: {word_counts.median():.1f} words\")\n",
    "                \n",
    "                # Check for duplicates\n",
    "                duplicate_count = full_data[text_col].duplicated().sum()\n",
    "                duplicate_percentage = (duplicate_count / len(full_data)) * 100\n",
    "                print(f\"  - Exact duplicates: {duplicate_count:,} ({duplicate_percentage:.1f}%)\")\n",
    "                \n",
    "                if duplicate_percentage > 10:\n",
    "                    print(\"    ‚ö†Ô∏è  High duplicate content detected\")\n",
    "                elif duplicate_percentage > 5:\n",
    "                    print(\"    ‚ö†Ô∏è  Moderate duplicate content detected\")\n",
    "                else:\n",
    "                    print(\"    ‚úÖ Low duplicate content\")\n",
    "        \n",
    "        # Missing values\n",
    "        missing_info = full_data.isnull().sum()\n",
    "        if missing_info.sum() > 0:\n",
    "            print(f\"\\nMissing values:\")\n",
    "            for col, missing_count in missing_info.items():\n",
    "                if missing_count > 0:\n",
    "                    percentage = (missing_count / len(full_data)) * 100\n",
    "                    print(f\"  - {col}: {missing_count:,} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No missing values detected\")\n",
    "        \n",
    "        return full_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy Category Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze redundancy datasets\n",
    "redundancy_datasets = datasets_config['datasets']['redundancy']\n",
    "redundancy_data = {}\n",
    "\n",
    "for dataset_name, config in redundancy_datasets.items():\n",
    "    data = analyze_dataset(dataset_name, config, 'redundancy')\n",
    "    if data is not None:\n",
    "        redundancy_data[dataset_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance Category Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze imbalance datasets\n",
    "imbalance_datasets = datasets_config['datasets']['imbalance']\n",
    "imbalance_data = {}\n",
    "\n",
    "for dataset_name, config in imbalance_datasets.items():\n",
    "    data = analyze_dataset(dataset_name, config, 'imbalance')\n",
    "    if data is not None:\n",
    "        imbalance_data[dataset_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Category Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze noise datasets\n",
    "noise_datasets = datasets_config['datasets']['noise']\n",
    "noise_data = {}\n",
    "\n",
    "for dataset_name, config in noise_datasets.items():\n",
    "    data = analyze_dataset(dataset_name, config, 'noise')\n",
    "    if data is not None:\n",
    "        noise_data[dataset_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers Category Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze outlier datasets\n",
    "outlier_datasets = datasets_config['datasets']['outliers']\n",
    "outlier_data = {}\n",
    "\n",
    "for dataset_name, config in outlier_datasets.items():\n",
    "    data = analyze_dataset(dataset_name, config, 'outliers')\n",
    "    if data is not None:\n",
    "        outlier_data[dataset_name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "Based on the analysis above, we can make the following observations and recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Count successfully loaded datasets\n",
    "total_loaded = len(redundancy_data) + len(imbalance_data) + len(noise_data) + len(outlier_data)\n",
    "total_configured = sum(len(datasets) for datasets in datasets_config['datasets'].values())\n",
    "\n",
    "print(f\"\\nDatasets successfully loaded: {total_loaded}/{total_configured}\")\n",
    "print(f\"\\nCategory breakdown:\")\n",
    "print(f\"  - Redundancy: {len(redundancy_data)} datasets\")\n",
    "print(f\"  - Imbalance: {len(imbalance_data)} datasets\")\n",
    "print(f\"  - Noise: {len(noise_data)} datasets\")\n",
    "print(f\"  - Outliers: {len(outlier_data)} datasets\")\n",
    "\n",
    "print(f\"\\nüìã NEXT STEPS:\")\n",
    "print(f\"1. Run baseline experiments on successfully loaded datasets\")\n",
    "print(f\"2. Implement data quality detection for automatic issue identification\")\n",
    "print(f\"3. Apply targeted preprocessing strategies\")\n",
    "print(f\"4. Compare preprocessing vs baseline performance\")\n",
    "print(f\"5. Generate comprehensive benchmark report\")\n",
    "\n",
    "if total_loaded < total_configured:\n",
    "    print(f\"\\n‚ö†Ô∏è  Some datasets failed to load. Consider:\")\n",
    "    print(f\"   - Checking internet connectivity for downloads\")\n",
    "    print(f\"   - Setting up Kaggle API credentials\")\n",
    "    print(f\"   - Using synthetic data for initial testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
